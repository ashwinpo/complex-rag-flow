{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5fd940-d1ab-4be2-9193-295ae6f0f7ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run pip install -r requirements.txt from terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d249ade-a0ff-49d5-9699-fbf7862d8095",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4aaed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import re\n",
    "import tempfile\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Watson Discovery\n",
    "from ibm_watson import DiscoveryV2\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "# watsonX\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from langchain_ibm import WatsonxLLM\n",
    "\n",
    "# LangChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2734d9a-cb6e-4cdc-be03-193a85b64a3f",
   "metadata": {},
   "source": [
    "# Load Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87fa7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "credentials = Credentials(\n",
    "                   url = os.getenv('WATSONX_URL'),\n",
    "                   api_key = os.getenv('WATSONX_APIKEY'),\n",
    "                  )\n",
    "try:\n",
    "    project_id = os.getenv(\"WATSONX_INSTANCE_ID\")\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id (hit enter): \")\n",
    "    \n",
    "\n",
    "authenticator = IAMAuthenticator(os.getenv('WATSONX_APIKEY'))\n",
    "discovery_project_id = os.getenv(\"DISCOVERY_PROJECT_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29304181-d7b6-4c8e-b147-ee0bfd45e3b3",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a99f159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/llama-3-70b-instruct\"\n",
    "\n",
    "# Use greedy model for most prompts\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.MAX_NEW_TOKENS: 200,\n",
    "}\n",
    "\n",
    "watsonx_llama3 = WatsonxLLM(\n",
    "    model_id=model_id,\n",
    "    url=credentials.get(\"url\"),\n",
    "    apikey=credentials.get(\"apikey\"),\n",
    "    project_id=project_id,\n",
    "    params=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6785dc2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Capitalism is a complex and multifaceted economic system that has both positive and negative impacts on society. While it has lifted millions of people out of poverty, a significant portion of the population remains in poverty, and income inequality has increased. Capitalism promotes innovation, efficiency, and economic growth, but it also creates social and environmental problems, such as exploitation of workers, environmental degradation, and concentration of wealth. Ultimately, whether capitalism is good or bad for society depends on how it is regulated and implemented, and whether its benefits are shared equitably among all members of society.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "watsonx_llama3.invoke('Argue if capitalism is good or bad for society. Summarize your conclusions in a concise sentences.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ba7233-796b-4e8f-826d-196e7ca6b56f",
   "metadata": {},
   "source": [
    "# Search - DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3078931-a094-48cb-86f8-63fcf3dbe950",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_tool = DuckDuckGoSearchResults(max_results=5)\n",
    "\n",
    "def parse_ddg_results(input_string:str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse DuckDuckGo search results\n",
    "    \n",
    "    Args:\n",
    "        input_string (str): Raw DuckDuckGo search output \n",
    "\n",
    "    Returns:\n",
    "        (List[str]): List of dictionaries of search matches\n",
    "    \"\"\"\n",
    "    # Regex to match each entry in the string\n",
    "    pattern = r'\\[snippet: (.*?), title: (.*?), link: (.*?)\\]'\n",
    "    \n",
    "    # Find all matches using regex\n",
    "    matches = re.findall(pattern, input_string)\n",
    "    \n",
    "    # Create a list of dictionaries based on the matches\n",
    "    data = [{'snippet': match[0], 'title': match[1], 'link': match[2]} for match in matches]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae5a59f8-65fb-4cc2-b4b8-da7f0cc509d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'snippet': \"Krishna talked with CNBC about his specific views on regulation, the business of generative AI and IBM's successes and mistakes. IBM CEO Arvind Krishna speaks at a panel session at the World ...\", 'title': 'IBM CEO Arvind Krishna CNBC interview', 'link': 'https://www.cnbc.com/2023/12/07/ibm-ceo-arvind-krishna-cnbc-interview.html'}, {'snippet': 'Lou Gerstner is an American businessman best known for the pivotal role he played in revitalizing the ailing IBM in the mid-1990s; he served as CEO of the company from 1993 to 2002. Gerstner studied engineering at Dartmouth College in Hanover, New Hampshire (B.A., 1963), where he graduated magna', 'title': 'Lou Gerstner | Biography, IBM, & Facts - Encyclopedia Britannica', 'link': 'https://www.britannica.com/money/Lou-Gerstner'}, {'snippet': \"Arvind Krishna's term at IBM as the CEO marks a new era for the tech giant. His tenure is bound to open new doors and herald an era of transformation coupled with digital advancement. Significance of IBM. IBM is an American multinational technology corporation headquartered in New York. It is known for its hardware and software products ...\", 'title': 'Arvind Krishna, CEO of IBM: Ushering an era of innovation and ...', 'link': 'https://etinsights.et-edge.com/arvind-krishna-ceo-of-ibm-ushering-an-era-of-innovation-and-transformation/'}, {'snippet': \"Hunt Scanlon Media is pleased to announce that Arvind Krishna, Chairman and Chief Executive Officer of IBM, has been named the recipient of Hunt Scanlon's 'Excellence in Culture' Award for 2024.\", 'title': \"Arvind Krishna, CEO of IBM, Selected as 2024 Hunt Scanlon 'Excellence ...\", 'link': 'https://finance.yahoo.com/news/arvind-krishna-ceo-ibm-selected-100000067.html'}]\n"
     ]
    }
   ],
   "source": [
    "# Test DuckDuckGo Search\n",
    "docs = web_search_tool.invoke(\"CEO of IBM?\")\n",
    "print(parse_ddg_results(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d44f5",
   "metadata": {},
   "source": [
    "## Discovery Related Prompts\n",
    "##### 1. Summarize Discovery Collection \n",
    "##### 2. Assign Discovery Collection Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063b6f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_collection_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are helpful assistant writing a short summary so a user know's what's included. \n",
    "    Summarize the folowing retrieved context. Limit your summary to 3 sentences. Don't include extraneous information! \n",
    "    Only respond with the summary with no preamble or explanation.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Context: {context} \n",
    "    Summary: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"context\"],\n",
    ")\n",
    "summary_chain = summarize_collection_prompt | watsonx_llama3 | StrOutputParser()\n",
    "\n",
    "name_collection_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are helpful assistant writing a topic name to assign this question. \n",
    "    Please provide a helpful topic name for this question and similar questions. Generally, it can be an IBM product name.\n",
    "    Only respond with the topic name with no preamble or explanation.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Topic Name: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "name_collection_chain = name_collection_prompt | watsonx_llama3 | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc16d8f",
   "metadata": {},
   "source": [
    "## Discovery Wrapper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8833cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Removes any non-alphanumeric and miscellaneous characters from Discovery search output\n",
    "    \n",
    "    Args:\n",
    "        state (str): Raw text with non-alphanumeric and miscellaneous characters such as HTML tags, etc.\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Cleaned text\n",
    "    \"\"\"\n",
    "    # Remove HTML tags\n",
    "    clean = re.compile('<.*?>')\n",
    "    cleaned_text = re.sub(clean, '', text)\n",
    "    \n",
    "    # Replace multiple newline characters with a single newline\n",
    "    cleaned_text = re.sub(r'\\n+', '\\n', cleaned_text)\n",
    "    \n",
    "    # Remove leading and trailing whitespace\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def watson_discovery_tool(query):\n",
    "    \"\"\"\n",
    "    Creates a tool to query IBM Watson Discovery for insights from unstructured data\n",
    "    The input query should be a natural language query.\n",
    "   \n",
    "    Args:\n",
    "        state (str): Input query\n",
    "\n",
    "    Returns:\n",
    "        state (str): Cleaned Discovery search output\n",
    "    \"\"\"\n",
    "    discovery = DiscoveryV2(version=\"2019-11-29\", authenticator=authenticator)\n",
    "    discovery.set_service_url(os.getenv(\"DISCOVERY_SERVICE_URL\"))\n",
    "\n",
    "    response = discovery.query(project_id=discovery_project_id, natural_language_query=query).get_result()\n",
    "    results = response[\"results\"]\n",
    "    passages = [x[\"document_passages\"] for x in results]\n",
    "    excerpts = [x[\"passage_text\"]  for l in passages for x in l]\n",
    "    context = \"\\n\\n\".join(excerpts)\n",
    "\n",
    "    return clean_text(context)\n",
    "\n",
    "def watson_discovery_summary_collections():\n",
    "    \"\"\"\n",
    "    Creates a dictionary with information about collections in a Discovery project\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Dictionary where each key-value pair is a Discovery collection ID and its corresponding summary\n",
    "    \"\"\"\n",
    "    discovery = DiscoveryV2(version=\"2019-11-29\", authenticator=authenticator)\n",
    "    discovery.set_service_url(os.getenv(\"DISCOVERY_SERVICE_URL\"))\n",
    "\n",
    "    # List collections\n",
    "    collections = discovery.list_collections(project_id=discovery_project_id).get_result()\n",
    "    \n",
    "    # Extract collection IDs\n",
    "    collection_ids = [collection['collection_id'] for collection in collections['collections']]\n",
    "    \n",
    "    # Initialize an empty dictionary\n",
    "    collection_summaries = {}\n",
    "\n",
    "    for collection in collection_ids:\n",
    "        response = discovery.query(project_id=\"ab6d11d1-e16e-4b87-9efe-3d1c5f2ce17a\", collection_ids= [collection], natural_language_query=\"\").get_result()\n",
    "        results = response[\"results\"]\n",
    "        passages = [x[\"document_passages\"] for x in results]\n",
    "        excerpts = [x[\"passage_text\"]  for l in passages for x in l]\n",
    "        context = \"\\n\\n\".join(excerpts)\n",
    "\n",
    "    # Run chain\n",
    "        context = clean_text(context)\n",
    "        summary = summary_chain.invoke({\"context\": context})\n",
    "        collection_summaries[collection] = clean_text(summary)\n",
    "        \n",
    "    return collection_summaries\n",
    "\n",
    "def watson_discovery_add_document(question, answer, collection_id):\n",
    "    \"\"\"\n",
    "    Adds a document to a specific collection in IBM Watson Discovery\n",
    "    \n",
    "    Args:\n",
    "        question (str): Input question\n",
    "        answer (str): Answer returned by invoking `watson_discovery_tool`\n",
    "        collection_id (str): Discovery collection to add answer document back to\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    discovery = DiscoveryV2(version=\"2019-11-29\", authenticator=authenticator)\n",
    "    discovery.set_service_url(os.getenv(\"DISCOVERY_SERVICE_URL\"))\n",
    "\n",
    "    question = question.strip()\n",
    "    answer = answer.strip()\n",
    "    document_content = f\"USER QUESTION: {question}\\n\\nUSEFUL ANSWER:\\n{answer}\"\n",
    "    print(document_content)\n",
    "    print(\"------------\")\n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False) as temp_file:\n",
    "            temp_file.write(document_content)\n",
    "            temp_file_path = temp_file.name\n",
    "\n",
    "    # Add the document to Watson Discovery using the temporary file\n",
    "    with open(temp_file_path, 'rb') as file:\n",
    "        response = discovery.add_document(\n",
    "            project_id=discovery_project_id,\n",
    "            collection_id=collection_id,\n",
    "            file=file\n",
    "        ).get_result()\n",
    "\n",
    "    os.remove(temp_file_path)\n",
    "    print(f\"Document added successfully. Document ID: {response['document_id']}\")\n",
    "    \n",
    "def watson_discovery_create_collection(question) -> str:\n",
    "    \"\"\"\n",
    "    Creates a collection in IBM Watson Discovery\n",
    "\n",
    "    Args:\n",
    "        question (str): Input question\n",
    "\n",
    "    Returns:\n",
    "        (str): Response from Discovery after adding a new collection\n",
    "    \"\"\"\n",
    "    # Run chain\n",
    "    name = name_collection_chain.invoke({\"question\": question}).strip()\n",
    "    discovery = DiscoveryV2(version=\"2019-11-29\", authenticator=authenticator)\n",
    "    discovery.set_service_url(os.getenv(\"DISCOVERY_SERVICE_URL\"))\n",
    "\n",
    "    response = discovery.create_collection(project_id=discovery_project_id,\n",
    "                                name=name).get_result()\n",
    "    \n",
    "    print(f\"New Collection successfully created. \\n Name: {name} \\n Collection ID: {response['collection_id']}\")\n",
    "    \n",
    "    return response['collection_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2326b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with model training, development, visual modeling, and synthetic data generation IBM watsonx.ai Foundation Models Library – available today IBM Granite Llama 3 models LAB Aligned models © © A © © © © granite\\nOther product and service names might be trademarks of IBM or other companies. A current list of IBM trademarks is available on ibm.com/trademark. Foundation models and Generative AI are bringing an inflection point in AI\\n| | \\\\ > F | ( S / > C | ¢ | | | | % 2 © 2023 IBM Corporation IBM's AI assistants use Foundation Models and Automation to orchestrate skill execution and reduce time and effort Customers, employees, and\\nSource links: Foundation model parameters: decoding and stopping criteria Foundation models Choosing a foundation model in watsonx. ai © © ® 14 © 2023 IBM Corporation Advantages of Retrieval Augmented Generation (RAG) RAG is a form of architecture that uses search results to enhance the generative model.\\n. | & | • Create a custom language model simply by uploading a text file with training phrases ; • Basic UI available to create STT Custom Models AM Customizations LM Customizations Docs • Available for download from Github Customiz..\\nOther product and service names might be trademarks of IBM or other companies. A current list of IBM trademarks is available on ibm.com/trademark. Produced in the United States of America June 2023 This document is current as of the initial date of publication and may be changed by IBM at any time.\\nUSER QUESTION: What foundation models can I use in watson assistant?\\nUSEFUL ANSWER:\\nYou can use the following foundation models in Watson Assistant:\\n1.\\nUSER QUESTION: What foundation models can I use in watson assistant?\\nUSEFUL ANSWER:\\nYou can use the following foundation models in Watson Assistant:\\n1.\\nUSER QUESTION: What foundation models can I use in watson assistant?\\nUSEFUL ANSWER:\\nYou can use the following foundation models in Watson Assistant:\\n1.\\nUSER QUESTION: What foundation models can I use in watson assistant?\\nUSEFUL ANSWER:\\nYou can use the following foundation models in Watson Assistant:\\n1.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Watson Discovery Tool\n",
    "watson_discovery_tool(\"what foundation models are available?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e922df30-0b06-430b-b670-ffa67bdc6d28",
   "metadata": {},
   "source": [
    "## Create collection summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9048a0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d34c4f1e-dd5b-2737-0000-018f976cd037': 'IBM Knowledge Catalog and Informatica Enterprise Data Catalog are both data cataloging solutions. They provide features for data governance, data quality, and data discovery. Both solutions offer similar functionalities for managing and organizing data.', 'e7b5cf24-2148-7ed5-0000-018f54532efc': 'IBM Watsonx is an AI and data platform that helps deploy and embed AI across businesses, with high-impact use cases like chatbots and employee productivity. Watson Assistant is a conversational AI application that can be used to deploy chatbots quickly. In Watson Assistant, you can use foundation models like IBM Granite Code LLM and Code Llama.', '6042175d-e2c0-b031-0000-018f5451ff1d': 'Here is a 3-sentence summary:\\nIBM Watsonx.data is an open, hybrid, and governed data store that helps scale AI workloads by providing a trusted data foundation. It offers fit-for-purpose query engines, built-in data governance, security, and automation. A data fabric architecture can simplify data access for users, addressing the challenges of dispersed, dynamic, and diverse data.', '583b032f-e9f6-8596-0000-018f5452b6b3': \"Watsonx Orchestrate is an intelligent assistant that boosts productivity by efficiently resolving tasks across platforms. It's part of IBM's strategy to implement AI assistants in various business areas, including customer care, sales, supply chain, procurement, finance, and HR. A new feature, Conversational Skills, is set to be released in April 2024.\"}\n"
     ]
    }
   ],
   "source": [
    "collection_summaries = watson_discovery_summary_collections()\n",
    "print(collection_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e656f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watson_discovery_create_collection(\"what is IBM Knowledge Catalog?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf93d5",
   "metadata": {},
   "source": [
    "## Helper Prompts for QA Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbaafe4-f7d1-4c36-8902-f687314f77b6",
   "metadata": {},
   "source": [
    "### Retrieval Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b008df98-8394-49da-8fb8-aefe2c90d03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "retrieval_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains any information useful to answer user's question, \n",
    "    grade it as relevant. If the document contains information that is relevant to only a portion of the question, grade it as relevant.\n",
    "    The goal is to filter out completely irrelevant retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "# Create chain\n",
    "retrieval_grader = retrieval_grader_prompt | watsonx_llama3 | JsonOutputParser()\n",
    "\n",
    "# Run chain\n",
    "question = \"What are Watson Orchestrate skills?\"\n",
    "docs = watson_discovery_tool(question)\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": docs}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a2eb28-b3d4-442b-ab16-b5fb727bbef9",
   "metadata": {},
   "source": [
    "### Query Reworder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e1fd779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': 'Watson Orchestrate skills list'}, {'query': 'Watson Orchestrate features'}, {'query': 'IBM Watson Orchestrate capabilities'}, {'query': 'Watson Orchestrate AI skills'}]\n"
     ]
    }
   ],
   "source": [
    "reword_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an in charge of querying a search engine on behalf of a user.\n",
    "    A user will provide you a question that you need to reword for optimal search on business documents. If there are multiple questions, break them down into multiple queries.\n",
    "    For example, if a user asks to compare the forecast in Chicago to New York, you should form queries such as \"Weather forecast NYC\", \"Weather forecast Chicago\", \"current weather NYC\", \"current weather Chicago\", etc.\n",
    "    Provide up to 4 queries in a JSON list with a single key 'query' for each query and no premable or explaination.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "# Create chain\n",
    "reword_chain = reword_prompt | watsonx_llama3 | JsonOutputParser()\n",
    "\n",
    "# Run chain\n",
    "question = \"What are Watson Orchestrate skills?\"\n",
    "generation = reword_chain.invoke({\"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06756154-7f6d-4acd-87cb-c7b5f475f8b3",
   "metadata": {},
   "source": [
    "### Query Reworder with document feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "693f48bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What are the skills of Watson Orchestrate Product Manager?'}\n"
     ]
    }
   ],
   "source": [
    "reword_feedback_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an in charge of querying a search engine on behalf of a user.\n",
    "    Analyze the current question and corresponding document. The current query is not optimal and needs to be reworded for better results. \n",
    "    Provide the query as a JSON with a single key 'query' and no preamble or explanation.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Query: {query} \n",
    "    Document: {document} \n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"query\", \"document\"],\n",
    ")\n",
    "\n",
    "# Create chain\n",
    "reword_feedback_chain = reword_feedback_prompt | watsonx_llama3 | JsonOutputParser()\n",
    "\n",
    "# Run chain\n",
    "question = \"What are Watson Orchestrate skills?\"\n",
    "docs = watson_discovery_tool(question)\n",
    "print(reword_feedback_chain.invoke({\"query\": question, \"document\": docs}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d00c638-07c8-4df7-9ae3-fc2afbe471a6",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d531a81-6d4d-405e-975a-01ef1c9679fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Watson Orchestrate skills are AI-powered skills that leverage Gen AI to accomplish new tasks or build new skills, and execute automations.\n"
     ]
    }
   ],
   "source": [
    "rag_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Answer the question completely while keeping the answer concise. Don't include extraneous information <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Create chain\n",
    "rag_chain = rag_prompt | watsonx_llama3 | StrOutputParser()\n",
    "\n",
    "# Run chain\n",
    "question = \"What are Watson Orchestrate skills?\"\n",
    "docs = watson_discovery_tool(question)\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e1f8a3-8bda-4c1f-b67b-969b238b86eb",
   "metadata": {},
   "source": [
    "### Hallucination Grader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b02a16dc-edaa-448d-bbc3-2512db1d82a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "# Create chain\n",
    "hallucination_grader = hallucination_grader_prompt | watsonx_llama3 | JsonOutputParser()\n",
    "\n",
    "# Run chain\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2d010-9892-4dce-90cf-ac0622417849",
   "metadata": {},
   "source": [
    "### Answer Grader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfa62c8a-4084-4868-9f99-86060886d877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "# Create chain\n",
    "answer_grader = answer_grader_prompt | watsonx_llama3 | JsonOutputParser()\n",
    "\n",
    "# Run chain\n",
    "answer_grader.invoke({\"question\": question,\"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62911607-4145-4659-834e-393834e3224e",
   "metadata": {},
   "source": [
    "### Query Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3beb5ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_query_router_prompt(collection_summaries):\n",
    "    \"\"\"\n",
    "    Routes a query to a specific Discovery collection based on relevance to collection summary\n",
    "\n",
    "    Args:\n",
    "        collection_summaries (dict): Dictionary where each key-value pair is a Discovery collection ID and its corresponding summary\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        (PromptTemplate): Query router prompt\n",
    "    \"\"\"\n",
    "    template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> \n",
    "    You are an expert at routing a query to the appropriate data source.\n",
    "    Use the following criteria to determine the data source:\\n\"\"\"\n",
    "    for cid, summary in collection_summaries.items():\n",
    "        template = template + f\"\\t- {cid}: {summary}\\n\"\n",
    "\n",
    "    template = template + \"\"\"\\t- web_search: If the query does not match any of the collections above.\n",
    "\n",
    "    Provide your decision as a JSON object with a single key 'datasource' and no preamble or explanation.\n",
    "    Query to route: {query} \n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "    route_query_prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"query\"],\n",
    "    )\n",
    "    \n",
    "    return route_query_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a3e9ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasource': '583b032f-e9f6-8596-0000-018f5452b6b3'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create prompt\n",
    "route_query_prompt = construct_query_router_prompt(collection_summaries)\n",
    "\n",
    "# Create chain\n",
    "route_query_chain = route_query_prompt | watsonx_llama3 | JsonOutputParser()\n",
    "\n",
    "# Run chain\n",
    "query = \"What are Watson Orchestrate skills?\"\n",
    "route_query_chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd59cdf-a04d-4b2e-b9cc-6a1b1e80a6c6",
   "metadata": {},
   "source": [
    "## Implement chains above as a control flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07fa3d08-6a86-4705-a28b-e2721070bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state of the pipeline\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "def grade_document(query, document, datasource):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to each query\n",
    "    If any document is not relevant, we will run web search\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "\n",
    "    # Score each document\n",
    "    filtered_docs = []\n",
    "    result = retrieval_grader.invoke({\"question\": query, \"document\": document.page_content})\n",
    "    grade = result['score']\n",
    "   \n",
    "    # Document relevant\n",
    "    if grade.lower() == \"yes\":\n",
    "        print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "        return document\n",
    "        \n",
    "    # Document not relevant\n",
    "    else:\n",
    "        print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "        \n",
    "        # Invoke web search to replace irrelevant document\n",
    "        if datasource != \"web_search\":\n",
    "            document = web_search(query)\n",
    "            result = retrieval_grader.invoke({\"question\": query, \"document\": document.page_content})\n",
    "            grade = result['score']\n",
    "            \n",
    "       # Generate new web results to replace irrelevant web search\n",
    "        i = 0\n",
    "        while grade.lower() != \"yes\" and i < 3:\n",
    "            print(\"---REWORDING WEB QUERY---\")\n",
    "\n",
    "            query = reword_feedback_chain.invoke({\"query\": query, \"document\": document.page_content})\n",
    "            document = web_search(query['query'])\n",
    "            result = retrieval_grader.invoke({\"question\": query, \"document\": document.page_content})\n",
    "            grade = result['score']\n",
    "\n",
    "            i+= 1\n",
    "        return document\n",
    "\n",
    "    \n",
    "    \n",
    "def web_search(query):\n",
    "    \"\"\"\n",
    "    Web search based based on the question\n",
    "\n",
    "    Args:\n",
    "        query (str): The query to search\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    \n",
    "    # Web search\n",
    "    str_docs = web_search_tool.invoke({\"query\": query})\n",
    "    docs = parse_ddg_results(str_docs)\n",
    "    web_results = \"\\n\".join([d[\"snippet\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    \n",
    "    documents = web_results\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4021f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def query_analyzer(state):\n",
    "    \"\"\"\n",
    "    Break down the question into multiple queries for search.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state of the pipeline\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updated state with generated queries\n",
    "    \"\"\"\n",
    "    print(\"---QUERY ANALYZER---\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # Generate queries using the reword_chain\n",
    "    queries = reword_chain.invoke({\"question\": question})\n",
    "    \n",
    "    # Append original question as a query as well\n",
    "    queries.append({\"query\": question})\n",
    "    \n",
    "    return {\"question\": question, \"queries\": queries}\n",
    "\n",
    "def route_query(query):\n",
    "    \"\"\"\n",
    "    Route query to Watson Discovery or web search using an LLM.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state of the pipeline\n",
    "        query (str): The query to route\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    print(\"---ROUTE QUERY---\")\n",
    "    \n",
    "    # Run chain\n",
    "    result = route_query_chain.invoke({\"query\": query})\n",
    "    datasource = result['datasource']\n",
    "    \n",
    "    return datasource\n",
    "\n",
    "\n",
    "\n",
    "def watson_discovery_retrieve(query, collection):\n",
    "    \"\"\"\n",
    "    Retrieve documents from Watson Discovery based on the collection.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query to search\n",
    "        collection (str): The selected collection\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updated state with retrieved documents\n",
    "    \"\"\"\n",
    "    print(f\"---WATSON DISCOVERY RETRIEVE ({collection})---\")\n",
    "    \n",
    "    # Retrieve documents from Watson Discovery\n",
    "    result = watson_discovery_tool(query)\n",
    "    \n",
    "    disc_results = Document(page_content=result)\n",
    "    \n",
    "    documents = disc_results\n",
    "    \n",
    "    return documents\n",
    "\n",
    "\n",
    "    \n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state of the pipeline\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score['score']\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "        grade = score['score']\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95950868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(user_question, query, datasource):\n",
    "    \"\"\"\n",
    "    Obtains documents to answer user question whether they are from web search or Discovery \n",
    "    Args:\n",
    "        user_question (str): User question\n",
    "        query (str): User query\n",
    "        datasource (str): Discovery collection ID\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        str: Documents from selected datasource \n",
    "    \"\"\"\n",
    "    print(f\"Processing query: {query}\")\n",
    "    \n",
    "    # Route the query\n",
    "    print(\"Datasource: \" + datasource)\n",
    "    \n",
    "    if datasource == \"web_search\":\n",
    "        documents = web_search(query)\n",
    "    else:\n",
    "        try:\n",
    "            summary = collection_summaries[datasource]\n",
    "        except:\n",
    "            print(\"Router returned a collection ID not in dictionary\")\n",
    "            return []\n",
    "        documents = watson_discovery_retrieve(query, datasource)\n",
    "        \n",
    "    \n",
    "    documents = grade_document(query, documents, datasource)\n",
    "    return documents\n",
    "\n",
    "def run_pipeline(question):\n",
    "    \"\"\"\n",
    "    Runs complete routing pipeline\n",
    "\n",
    "    Args:\n",
    "        question (str): User question\n",
    "\n",
    "    Returns:\n",
    "        (str): Final state\n",
    "    \"\"\"\n",
    "    # Get the initial question\n",
    "    state = {\"question\": question}\n",
    "    \n",
    "    # Run the query analyzer\n",
    "    state = query_analyzer(state)\n",
    "    queries = state[\"queries\"]\n",
    "\n",
    "    state[\"datasources\"] = Parallel(n_jobs=-1, prefer=\"threads\")(delayed(route_query)(query['query']) for query in queries)\n",
    "    datasources = state[\"datasources\"]\n",
    "    \n",
    "    # Process each query in parallel using joblib\n",
    "    documents = Parallel(n_jobs=-1, prefer=\"threads\")(delayed(process_query)(state[\"question\"], query['query'], datasource)\n",
    "                                                      for query, datasource in zip(queries, datasources))\n",
    "    \n",
    "    state[\"documents\"] = documents\n",
    "    \n",
    "    state = generate(state)\n",
    "    state[\"answer_class\"] = grade_generation_v_documents_and_question(state)\n",
    "    \n",
    "    # Print the final results\n",
    "    print(\"Final Answer:\\n\" + state[\"generation\"])\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970acbc-bb02-45be-b523-91e54f009b4b",
   "metadata": {},
   "source": [
    "# Run sample pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e8539cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---QUERY ANALYZER---\n",
      "---ROUTE QUERY------ROUTE QUERY---\n",
      "\n",
      "---ROUTE QUERY---\n",
      "---ROUTE QUERY---\n",
      "---ROUTE QUERY---\n",
      "Processing query: Watson Assistant foundation models listProcessing query: Foundation models supported by Watson Assistant\n",
      "Datasource: e7b5cf24-2148-7ed5-0000-018f54532efc\n",
      "---WATSON DISCOVERY RETRIEVE (e7b5cf24-2148-7ed5-0000-018f54532efc)---\n",
      "\n",
      "Datasource: e7b5cf24-2148-7ed5-0000-018f54532efc\n",
      "---WATSON DISCOVERY RETRIEVE (e7b5cf24-2148-7ed5-0000-018f54532efc)---\n",
      "Processing query: Watson Assistant AI models\n",
      "Datasource: e7b5cf24-2148-7ed5-0000-018f54532efc\n",
      "---WATSON DISCOVERY RETRIEVE (e7b5cf24-2148-7ed5-0000-018f54532efc)---\n",
      "Processing query: Pre-trained models in Watson Assistant\n",
      "Datasource: e7b5cf24-2148-7ed5-0000-018f54532efc\n",
      "---WATSON DISCOVERY RETRIEVE (e7b5cf24-2148-7ed5-0000-018f54532efc)---\n",
      "Processing query: What foundation models can I use in watson assistant?\n",
      "Datasource: e7b5cf24-2148-7ed5-0000-018f54532efc\n",
      "---WATSON DISCOVERY RETRIEVE (e7b5cf24-2148-7ed5-0000-018f54532efc)---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GENERATE---\n",
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "Final Answer:\n",
      "\n",
      "\n",
      "You can use the following foundation models in Watson Assistant:\n",
      "\n",
      "1. Code Llama (an AI model built on top of Llama 2, fine-tuned for generating and discussing code)\n",
      "2. Flan-t5-xxl (an 11 billion parameter model based on the Flan-15 family)\n",
      "3. Custom-ansible-model-v1 (a model customized using Prompt Tuning)\n",
      "\n",
      "Additionally, Watson Assistant also includes several pre-built, extension starter kits for external LLMs, and you can experiment with foundation models and build prompts for various use cases and tasks.\n",
      "Time to execute: 30.689491987228394\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# question = \"How does watson orchestrate differ from watson assistant?\"\n",
    "# question = \"How does IBM Knowledge Catalog compare to Informatica?\"\n",
    "question = \"What foundation models can I use in watson assistant?\"\n",
    "result = run_pipeline(question)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time to execute: \" + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "354915ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER QUESTION: What foundation models can I use in watson assistant?\n",
      "\n",
      "USEFUL ANSWER:\n",
      "You can use the following foundation models in Watson Assistant:\n",
      "\n",
      "1. Code Llama (an AI model built on top of Llama 2, fine-tuned for generating and discussing code)\n",
      "2. Flan-t5-xxl (an 11 billion parameter model based on the Flan-15 family)\n",
      "3. Custom-ansible-model-v1 (a model customized using Prompt Tuning)\n",
      "\n",
      "Additionally, Watson Assistant also includes several pre-built, extension starter kits for external LLMs, and you can experiment with foundation models and build prompts for various use cases and tasks.\n",
      "------------\n",
      "Document added successfully. Document ID: faa528a3-1fc4-4a7f-bbdc-e3ee0cff6bb1\n"
     ]
    }
   ],
   "source": [
    "# Add generated answer back into Discovery collection as a new document\n",
    "if result[\"answer_class\"] == \"useful\":\n",
    "    collection_id = route_query_chain.invoke({\"query\": question})[\"datasource\"]\n",
    "    \n",
    "    if collection_id == \"web_search\": # There is no relevant collection so let's create one\n",
    "        collection_id = watson_discovery_create_collection(question)\n",
    "        summary = summary_chain.invoke({\"context\": result[\"generation\"]})\n",
    "        collection_summaries[collection_id] = summary\n",
    "        \n",
    "    watson_discovery_add_document(question, result[\"generation\"], collection_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reflect",
   "language": "python",
   "name": "reflect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b1234d2fdb3d81c7c62eb5cb9d4f98d639f6682094e7fc7ea2d35604c5ac668"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
